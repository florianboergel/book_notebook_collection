{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts MOM model data into a readable format for the [interactivate validator](http://rshiny.io-warnemuende.de/radtke/validator/)\n",
    "\n",
    "> see https://youtu.be/S-UkKqyolJc for a full tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import os, glob, re\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validator folder already exsists\n"
     ]
    }
   ],
   "source": [
    "BEGIN               = 1961\n",
    "END                 = 2010\n",
    "STATION_SYNTAX      = \"rregion_\"\n",
    "variables_in_model  = [\"salt\"]\n",
    "validator_names     = [\"MODEL_SALIN\"]\n",
    "\n",
    "DIR             = \"/silor/boergel/paper/bmip/data/MOM/balt-3nm-skag-v02-r04_\"\n",
    "\n",
    "if os.path.isdir(\"for_validator\") == True:\n",
    "    print(\"Validator folder already exsists\")\n",
    "else:\n",
    "    os.mkdir('for_validator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(BEGIN, END):\n",
    "    station_list = [x for x in glob.glob(DIR + str(i) +'/*'+ STATION_SYNTAX +'*')]\n",
    "    for station in station_list:\n",
    "        if \"transect\" in station:\n",
    "            continue\n",
    "        STATION_NAME = station.split(STATION_SYNTAX)[1].split(\".nc.\")[0]\n",
    "        try:\n",
    "            ds = xr.open_dataset(station)\n",
    "            xt_ocean_pattern = re.compile(\"xt_ocean*\")\n",
    "            xt_ocean = [x for x in ds.dims if xt_ocean_pattern.match(x)][0]\n",
    "            yt_ocean_pattern = re.compile(\"yt_ocean*\")\n",
    "            yt_ocean = [x for x in ds.dims if yt_ocean_pattern.match(x)][0]\n",
    "            depth_pattern = re.compile(\"st_ocean_*\")\n",
    "            depth_name = [x for x in ds.dims if depth_pattern.match(x)][0]\n",
    "\n",
    "\n",
    "            ds = ds.rename({depth_name:\"z\"})\n",
    "            ds = ds[variables_in_model].squeeze()\n",
    "            for var in range(len(variables_in_model)):\n",
    "                ds = ds.rename({variables_in_model[var]:validator_names[var]})\n",
    "            ds.to_netcdf(\"for_validator/\" + STATION_NAME + \"_\" + str(i) + \".nc\")\n",
    "        except:\n",
    "#                 print(\"{} did not work\".format(STATION_NAME))\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEGotlandBasin\n",
      "ArkonaBY2\n",
      "GulfFinlandLL7\n",
      "FehmarnBelt\n",
      "GotlandDeepBY15\n",
      "BothnianSeaSR5\n",
      "GulfofFinlandF1\n",
      "LandskronaW\n",
      "AnholtE\n",
      "GdanskDeep\n",
      "GreatBelt\n",
      "BornholmDeepBY5\n",
      "BothnianBayF9\n",
      "GulfofRiga\n",
      "LandsortDeepBY31\n",
      "LandskronaW\n"
     ]
    }
   ],
   "source": [
    "for station in station_list:\n",
    "    try:\n",
    "        if \"transect\" in station:\n",
    "            continue\n",
    "        STATION_NAME = station.split(STATION_SYNTAX)[1].split(\".nc.\")[0]\n",
    "        print(STATION_NAME)\n",
    "        ds = xr.open_mfdataset(\"for_validator/\" + STATION_NAME+\"_*.nc\")\n",
    "        ds.to_netcdf(\"for_validator/\" + STATION_NAME + \".nc\")\n",
    "    except Exception as e:\n",
    "        print(STATION_NAME, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in station_list:\n",
    "    if \"transect\" in station:\n",
    "        continue\n",
    "    STATION_NAME = station.split(STATION_SYNTAX)[1].split(\".nc.\")[0]\n",
    "    for file in glob.glob(\"for_validator/\" + STATION_NAME+\"_*.nc\"):\n",
    "        os.remove(file)\n",
    "for file in glob.glob(\"for_validator/trans*\"):\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATION_NAMES = [station.split(\"for_validator/\")[1] for station in glob.glob(\"for_validator/*\")]\n",
    "STATION_NAMES_VALIDATOR = [\"AnholtE\",\"by2\", \"by5\", \"f9\", \"sr5\", \"fehmarn\", \"gdansk\", \"by15\", \"greatbelt\", \"ll7\", \"f1\", \"gulfofriga\", \"by31\", \"segotlandbasin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATION_NAMES = sorted(STATION_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-45ee1b4d187e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTATION_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"for_validator/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_validator/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSTATION_NAMES_VALIDATOR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".nc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for count, station in enumerate(STATION_NAMES):\n",
    "    os.rename(\"for_validator/\" + station, \"for_validator/\" + STATION_NAMES_VALIDATOR[count] + \".nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(1) Python 3",
   "language": "python",
   "name": "iow_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
